{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Data Collector for Sentiment Analysis\n",
    "\n",
    "This notebook is used to collect tweets for the iPhone sentiment analysis project. It interfaces with the Twitter API to gather tweets mentioning the product, which will later be used for sentiment classification.\n",
    "\n",
    "Authors: [Enricco Gemha](https://github.com/G3mha), [Marcelo Barranco](https://github.com/Maraba23), [Rafael Leventhal](https://github.com/rafaelcl292)\n",
    "\n",
    "Date: 2021-09-27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Setting Up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Required Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Installing Tweepy for Twitter API access\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Twitter Authentication\n",
    "\n",
    "* Account: **@gemhadventures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Twitter authentication data:\n",
    "\n",
    "# Twitter account identifier: @gemhadventures\n",
    "\n",
    "# Reading the JSON file\n",
    "with open('auth2.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "# Configuring the library\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Steps for Building the Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Selection and Tweet Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Selected product:\n",
    "product = 'iphone'\n",
    "\n",
    "# Minimum number of messages to capture:\n",
    "n = 1000\n",
    "# Minimum number of messages for the training set:\n",
    "t = 750\n",
    "\n",
    "# Language filter, choose one from ISO 639-1 table\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturing data from Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create an object for capturing\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# Start capturing, for more details: see tweepy documentation\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=product, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    \n",
    "    try:\n",
    "        # Try to access 'retweeted_status' attribute\n",
    "        # If message doesn't have this attribute, it raises an error\n",
    "        # and goes to the \"except\" clause\n",
    "        msg.retweeted_status.full_text\n",
    "    except AttributeError:  \n",
    "        # Enters here whenever the tweet is not a retweet\n",
    "        msgs.append(msg.full_text.lower())\n",
    "\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    temp_unique = list(set(list(msgs)))\n",
    "    if len(temp_unique) >= n:\n",
    "        break\n",
    "\n",
    "# Shuffling messages to reduce potential bias\n",
    "shuffle(msgs)\n",
    "len(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate messages\n",
    "msgs = list(set(list(msgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data to an Excel spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Check if the file doesn't exist to avoid overwriting a completed set\n",
    "if not os.path.isfile('./{0}.xlsx'.format(product)):\n",
    "    \n",
    "    # Open file for writing\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(product))\n",
    "\n",
    "    # Divide the message set into two spreadsheets\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    # Close the file\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Manual Message Classification\n",
    "\n",
    "This step is done manually using Excel.\n",
    "\n",
    "**Important: If you classify a small percentage of tweets as relevant or not relevant, you should return to this notebook and collect more diverse tweets about the chosen product.**\n",
    "\n",
    "The classification system is as follows:\n",
    "\n",
    "* **VERY IRRELEVANT (0)**: Off-topic tweets, unrelated to iPhone, or tweets with minimal content (e.g., just a hashtag)\n",
    "* **IRRELEVANT (1)**: Sales advertisements (e.g., \"Buy now at Magalu\")\n",
    "* **NEUTRAL (2)**: Jokes about iPhone (e.g., \"iPhone is like a mini Corsa lol\")\n",
    "* **RELEVANT (3)**: Indirect comments related to iPhone (e.g., \"My science teacher spent 30 minutes just talking about his new iPhone\")\n",
    "* **VERY RELEVANT (4)**: Direct comments about iPhone - opinions, questions, or purchase intent (e.g., \"iPhone 13 will have to wait a bit longer to reach my hands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After collecting and manually classifying the tweets, the next step is to process this data using the sentiment classifier notebook (`tweet_sentiment_classifier.ipynb`). That notebook will implement the Naive Bayes algorithm to automatically categorize tweets based on their relevance and sentiment toward the iPhone product."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9fd6c6be56567dc879efe7db14b5e3ce588c472dd9c12b78c63f32e96bcc071"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
